# ğŸ“Š Guia Completo do Prometheus - Car Build

## ğŸ¯ O que foi configurado?

O Prometheus Ã© um sistema de **monitoramento e alerta** que coleta mÃ©tricas dos seus serviÃ§os a cada 10 segundos. Pense nele como um "painel de controle" que mostra o que estÃ¡ acontecendo na sua aplicaÃ§Ã£o em tempo real.

### âœ… ServiÃ§os Monitorados:

1. **P-API (Gateway FastAPI)** - porta 8000
   - Total de requisiÃ§Ãµes HTTP
   - LatÃªncia (tempo de resposta)
   - RequisiÃ§Ãµes ativas
   - Chamadas gRPC para outros serviÃ§os

2. **Server A (CatÃ¡logo)** - porta gRPC 50051, mÃ©tricas 9091
   - RequisiÃ§Ãµes gRPC
   - Queries no PostgreSQL
   - ConexÃµes ativas com banco
   - Tempo de resposta das queries

3. **Server B (Pricing)** - porta gRPC 50052, mÃ©tricas 9092
   - CÃ¡lculos de orÃ§amento
   - Compras processadas
   - Valor total vendido
   - Tempo de processamento

---

## ğŸš€ Como Usar

### 1ï¸âƒ£ Iniciar o Prometheus

```bash
cd /home/dutra/codigos/PSPD_2025.2_Projeto_Final/Car_Build
./start-with-prometheus.sh
```

Isso iniciarÃ¡ o Prometheus. Ele ficarÃ¡ rodando e coletando mÃ©tricas automaticamente.

### 2ï¸âƒ£ Iniciar seus serviÃ§os

Em outro terminal, inicie seus serviÃ§os normalmente:

```bash
# Se estiver usando Docker Compose
cd Car_Build
docker-compose up

# OU se estiver usando Kind
./setup-kind-cluster.sh

# OU manualmente (cada um em um terminal separado)
# Terminal 1 - P-API
cd Car_Build/P-Api
source venv/bin/activate
uvicorn app:app --host 0.0.0.0 --port 8000

# Terminal 2 - Server A
cd Car_Build/Microservices/serverA-microsservice
node index.js

# Terminal 3 - Server B
cd Car_Build/Microservices/serverB-microsservice
node index.js

# Terminal 4 - Frontend
cd Car_Build/WebClient
npm start
```

### 3ï¸âƒ£ Acessar o Prometheus

Abra no navegador: **http://localhost:9090**

---

## ğŸ“ˆ Como Ver as MÃ©tricas

### Interface do Prometheus

1. **Targets (Status > Targets)**
   - Mostra quais serviÃ§os estÃ£o sendo monitorados
   - Verde = serviÃ§o respondendo âœ…
   - Vermelho = serviÃ§o com problema âŒ

2. **Graph (Menu principal)**
   - Digite queries para visualizar mÃ©tricas
   - Pode ver em grÃ¡fico ou tabela

---

## ğŸ” Queries Ãšteis para Testes de Carga

### ğŸ“Š **MÃ©tricas de RequisiÃ§Ãµes HTTP (P-API)**

```promql
# Total de requisiÃ§Ãµes por segundo
rate(p_api_requests_total[1m])

# RequisiÃ§Ãµes por endpoint
sum by (endpoint) (p_api_requests_total)

# Taxa de erro (requisiÃ§Ãµes com status 500)
sum(rate(p_api_requests_total{status="500"}[1m]))

# RequisiÃ§Ãµes ativas no momento
p_api_active_requests

# LatÃªncia mÃ©dia por endpoint (em segundos)
rate(p_api_request_duration_seconds_sum[1m]) / rate(p_api_request_duration_seconds_count[1m])

# Percentil 95 da latÃªncia (95% das requisiÃ§Ãµes sÃ£o mais rÃ¡pidas que isso)
histogram_quantile(0.95, rate(p_api_request_duration_seconds_bucket[5m]))

# Percentil 99 da latÃªncia (apenas 1% das requisiÃ§Ãµes sÃ£o mais lentas)
histogram_quantile(0.99, rate(p_api_request_duration_seconds_bucket[5m]))
```

### ğŸ—„ï¸ **MÃ©tricas do Banco de Dados (Server A)**

```promql
# Total de queries por segundo
rate(server_a_db_queries_total[1m])

# Taxa de erro em queries
sum(rate(server_a_db_queries_total{status="error"}[1m]))

# ConexÃµes ativas com o banco
server_a_db_connections_active

# Tempo mÃ©dio de query
rate(server_a_db_query_duration_seconds_sum[1m]) / rate(server_a_db_query_duration_seconds_count[1m])
```

### ğŸ¯ **MÃ©tricas gRPC (Server A e B)**

```promql
# RequisiÃ§Ãµes gRPC por segundo no Server A
rate(server_a_grpc_requests_total[1m])

# RequisiÃ§Ãµes gRPC por segundo no Server B
rate(server_b_grpc_requests_total[1m])

# Taxa de sucesso Server A (%)
sum(rate(server_a_grpc_requests_total{status="success"}[1m])) / sum(rate(server_a_grpc_requests_total[1m])) * 100

# LatÃªncia mÃ©dia gRPC Server A
rate(server_a_grpc_request_duration_seconds_sum[1m]) / rate(server_a_grpc_request_duration_seconds_count[1m])
```

### ğŸ’° **MÃ©tricas de NegÃ³cio (Server B)**

```promql
# Total de cÃ¡lculos de orÃ§amento
server_b_calculos_realizados_total

# Total de compras processadas
server_b_compras_processadas_total

# Valor total em vendas (R$)
server_b_valor_total_compras_reais

# Compras por minuto
rate(server_b_compras_processadas_total[1m]) * 60

# Ticket mÃ©dio (valor mÃ©dio por compra)
server_b_valor_total_compras_reais / server_b_compras_processadas_total{status="CONFIRMADO"}
```

### ğŸ’» **MÃ©tricas de Sistema (CPU, MemÃ³ria)**

```promql
# Uso de CPU por processo (%)
rate(process_cpu_seconds_total[1m]) * 100

# Uso de memÃ³ria (MB)
process_resident_memory_bytes / 1024 / 1024

# MemÃ³ria usada pelo Server A
process_resident_memory_bytes{job="server-a"} / 1024 / 1024
```

---

## ğŸ§ª Fazendo Testes de Carga

### PreparaÃ§Ã£o

1. **Inicie o Prometheus**: `./start-with-prometheus.sh`
2. **Inicie todos os serviÃ§os** (P-API, Server A, Server B, Frontend)
3. **Acesse o Prometheus**: http://localhost:9090
4. **Abra o frontend**: http://localhost:3000

### Ferramentas para Testes de Carga

#### ğŸ”¹ OpÃ§Ã£o 1: Apache Bench (ab)

```bash
# Instalar
sudo apt install apache2-utils

# Teste simples - 1000 requisiÃ§Ãµes, 10 concorrentes
ab -n 1000 -c 10 http://localhost:8000/health

# Teste com POST (ajuste o JSON conforme seu endpoint)
ab -n 500 -c 20 -p payload.json -T application/json http://localhost:8000/get-pecas
```

#### ğŸ”¹ OpÃ§Ã£o 2: wrk (mais poderoso)

```bash
# Instalar
sudo apt install wrk

# Teste durante 30 segundos, 10 threads, 100 conexÃµes
wrk -t10 -c100 -d30s http://localhost:8000/health

# Teste com script Lua para POST
wrk -t10 -c50 -d60s -s post.lua http://localhost:8000/get-pecas
```

#### ğŸ”¹ OpÃ§Ã£o 3: k6 (recomendado para testes complexos)

```bash
# Instalar
sudo snap install k6

# Criar script de teste (test.js)
cat > test.js << 'EOF'
import http from 'k6/http';
import { sleep } from 'k6';

export let options = {
  vus: 10, // 10 usuÃ¡rios virtuais
  duration: '30s', // duraÃ§Ã£o do teste
};

export default function () {
  http.get('http://localhost:8000/health');
  sleep(1);
}
EOF

# Executar teste
k6 run test.js
```

### Durante o Teste

**No Prometheus**, monitore em tempo real:

```promql
# RequisiÃ§Ãµes por segundo
rate(p_api_requests_total[10s])

# LatÃªncia P99 (99% das requisiÃ§Ãµes)
histogram_quantile(0.99, rate(p_api_request_duration_seconds_bucket[1m]))

# Erros por segundo
rate(p_api_requests_total{status=~"5.."}[10s])
```

---

## ğŸ“Š Exemplo de Teste Completo

### CenÃ¡rio: Teste de Carga no Endpoint de PeÃ§as

```bash
# 1. Preparar payload
cat > get-pecas.json << 'EOF'
{
  "modelo": "civic",
  "ano": 2020
}
EOF

# 2. Executar teste com curl em loop (simples)
for i in {1..100}; do
  curl -X POST http://localhost:8000/get-pecas \
    -H "Content-Type: application/json" \
    -d @get-pecas.json &
done

# 3. No Prometheus, execute estas queries:
```

**Queries para analisar durante o teste:**

```promql
# 1. Taxa de requisiÃ§Ãµes
rate(p_api_requests_total{endpoint="/get-pecas"}[30s])

# 2. LatÃªncia P95
histogram_quantile(0.95, rate(p_api_request_duration_seconds_bucket{endpoint="/get-pecas"}[1m]))

# 3. Queries no banco (Server A)
rate(server_a_db_queries_total[30s])

# 4. RequisiÃ§Ãµes gRPC do P-API para Server A
rate(p_api_grpc_calls_total{service="server-a"}[30s])
```

---

## ğŸ¯ MÃ©tricas Importantes para Analisar

### Durante Testes de Carga

| MÃ©trica | O que observar | Valores bons |
|---------|----------------|--------------|
| **LatÃªncia P95** | 95% das requisiÃ§Ãµes | < 200ms |
| **LatÃªncia P99** | 99% das requisiÃ§Ãµes | < 500ms |
| **Taxa de Erro** | RequisiÃ§Ãµes 5xx | < 1% |
| **Throughput** | Req/segundo | Depende do hardware |
| **ConexÃµes DB** | Pool do PostgreSQL | < 20 (seu max) |
| **RequisiÃ§Ãµes Ativas** | ConcorrÃªncia | NÃ£o deve crescer indefinidamente |

---

## ğŸ”§ Troubleshooting

### Prometheus nÃ£o estÃ¡ coletando mÃ©tricas

```bash
# Verificar se os serviÃ§os estÃ£o expondo /metrics
curl http://localhost:8000/metrics  # P-API
curl http://localhost:9091/metrics  # Server A
curl http://localhost:9092/metrics  # Server B

# Ver status no Prometheus
# Acesse: http://localhost:9090/targets
```

### ServiÃ§o aparece como "DOWN" no Prometheus

1. Verifique se o serviÃ§o estÃ¡ rodando
2. Verifique se a porta estÃ¡ correta no `prometheus.yml`
3. Verifique se nÃ£o hÃ¡ firewall bloqueando

### Instalar dependÃªncias que faltam

```bash
# Python (P-API)
cd Car_Build/P-Api
pip install prometheus-client

# Node.js (Server A e B)
cd Car_Build/Microservices
npm install prom-client express
```

---

## ğŸ“š Queries AvanÃ§adas

### Comparar performance entre serviÃ§os

```promql
# LatÃªncia de todos os serviÃ§os
(rate(p_api_request_duration_seconds_sum[5m]) / rate(p_api_request_duration_seconds_count[5m])) or
(rate(server_a_grpc_request_duration_seconds_sum[5m]) / rate(server_a_grpc_request_duration_seconds_count[5m])) or
(rate(server_b_grpc_request_duration_seconds_sum[5m]) / rate(server_b_grpc_request_duration_seconds_count[5m]))
```

### Taxa de sucesso geral do sistema

```promql
sum(rate(p_api_requests_total{status!~"5.."}[5m])) / sum(rate(p_api_requests_total[5m])) * 100
```

### RequisiÃ§Ãµes por endpoint (top 5)

```promql
topk(5, sum by (endpoint) (rate(p_api_requests_total[5m])))
```

---

## ğŸ“ PrÃ³ximos Passos

1. **Grafana** (opcional): Interface mais bonita para visualizar mÃ©tricas
   - `docker run -d -p 3001:3000 grafana/grafana`
   - Acesse http://localhost:3001
   - Configure Prometheus como datasource: http://localhost:9090

2. **Alertas**: Configure alertas para ser notificado de problemas

3. **Dashboards**: Crie dashboards personalizados no Prometheus ou Grafana

---

## ğŸ’¡ Dicas

- Use intervalos `[1m]` ou `[5m]` nas queries para suavizar variaÃ§Ãµes
- `rate()` Ã© melhor que `increase()` para ver velocidade
- Percentis (P95, P99) sÃ£o mais Ãºteis que mÃ©dias para latÃªncia
- Monitore sempre CPU e memÃ³ria durante testes de carga

---

Configurado por: GitHub Copilot ğŸ¤–
Data: 29/11/2025
