# ğŸ“Š Cheat Sheet - Queries Prometheus para Testes de Carga

## ğŸ¯ Copy & Paste - Queries Essenciais

### ğŸ“ˆ PERFORMANCE GERAL

```promql
# Taxa de requisiÃ§Ãµes por segundo (throughput)
rate(p_api_requests_total[1m])

# RequisiÃ§Ãµes por segundo por endpoint
sum by (endpoint) (rate(p_api_requests_total[1m]))

# Total acumulado de requisiÃ§Ãµes
sum(p_api_requests_total)

# RequisiÃ§Ãµes ativas neste momento
p_api_active_requests
```

### âš¡ LATÃŠNCIA (TEMPO DE RESPOSTA)

```promql
# LatÃªncia mÃ©dia em milissegundos
rate(p_api_request_duration_seconds_sum[1m]) / rate(p_api_request_duration_seconds_count[1m]) * 1000

# LatÃªncia P50 (mediana) - 50% das requisiÃ§Ãµes sÃ£o mais rÃ¡pidas
histogram_quantile(0.50, rate(p_api_request_duration_seconds_bucket[5m])) * 1000

# LatÃªncia P95 - 95% das requisiÃ§Ãµes sÃ£o mais rÃ¡pidas
histogram_quantile(0.95, rate(p_api_request_duration_seconds_bucket[5m])) * 1000

# LatÃªncia P99 - 99% das requisiÃ§Ãµes sÃ£o mais rÃ¡pidas
histogram_quantile(0.99, rate(p_api_request_duration_seconds_bucket[5m])) * 1000

# LatÃªncia mÃ¡xima observada
max_over_time(p_api_request_duration_seconds_sum[5m])
```

### ğŸš¨ ERROS E TAXA DE SUCESSO

```promql
# Taxa de erro (requisiÃ§Ãµes 5xx por segundo)
sum(rate(p_api_requests_total{status=~"5.."}[1m]))

# Taxa de erro em porcentagem
(sum(rate(p_api_requests_total{status=~"5.."}[1m])) / sum(rate(p_api_requests_total[1m]))) * 100

# Taxa de sucesso (%)
(sum(rate(p_api_requests_total{status=~"2.."}[1m])) / sum(rate(p_api_requests_total[1m]))) * 100

# RequisiÃ§Ãµes por status code
sum by (status) (rate(p_api_requests_total[1m]))
```

### ğŸ’¾ BANCO DE DADOS (Server A)

```promql
# Queries por segundo
rate(server_a_db_queries_total[1m])

# Taxa de erro em queries
sum(rate(server_a_db_queries_total{status="error"}[1m]))

# ConexÃµes ativas com PostgreSQL
server_a_db_connections_active

# Tempo mÃ©dio de query em milissegundos
(rate(server_a_db_query_duration_seconds_sum[1m]) / rate(server_a_db_query_duration_seconds_count[1m])) * 1000

# Queries mais lentas (P99)
histogram_quantile(0.99, rate(server_a_db_query_duration_seconds_bucket[5m])) * 1000
```

### ğŸ”Œ gRPC (Server A e B)

```promql
# RequisiÃ§Ãµes gRPC Server A por segundo
rate(server_a_grpc_requests_total[1m])

# RequisiÃ§Ãµes gRPC Server B por segundo
rate(server_b_grpc_requests_total[1m])

# Taxa de sucesso gRPC Server A (%)
(sum(rate(server_a_grpc_requests_total{status="success"}[1m])) / sum(rate(server_a_grpc_requests_total[1m]))) * 100

# LatÃªncia mÃ©dia gRPC Server A (ms)
(rate(server_a_grpc_request_duration_seconds_sum[1m]) / rate(server_a_grpc_request_duration_seconds_count[1m])) * 1000

# LatÃªncia mÃ©dia gRPC Server B (ms)
(rate(server_b_grpc_request_duration_seconds_sum[1m]) / rate(server_b_grpc_request_duration_seconds_count[1m])) * 1000
```

### ğŸ’° MÃ‰TRICAS DE NEGÃ“CIO (Server B)

```promql
# CÃ¡lculos de orÃ§amento por minuto
rate(server_b_calculos_realizados_total[1m]) * 60

# Compras processadas por minuto
rate(server_b_compras_processadas_total{status="CONFIRMADO"}[1m]) * 60

# Valor total vendido (R$)
server_b_valor_total_compras_reais

# Taxa de conversÃ£o (compras / cÃ¡lculos) em %
(server_b_compras_processadas_total / server_b_calculos_realizados_total) * 100

# Ticket mÃ©dio (valor mÃ©dio por compra)
server_b_valor_total_compras_reais / server_b_compras_processadas_total{status="CONFIRMADO"}
```

### ğŸ’» RECURSOS DO SISTEMA

```promql
# Uso de CPU por serviÃ§o (%)
rate(process_cpu_seconds_total[1m]) * 100

# Uso de memÃ³ria em MB
process_resident_memory_bytes / 1024 / 1024

# Uso de memÃ³ria do P-API
process_resident_memory_bytes{job="p-api"} / 1024 / 1024

# Uso de memÃ³ria do Server A
process_resident_memory_bytes{job="server-a"} / 1024 / 1024

# Uso de memÃ³ria do Server B
process_resident_memory_bytes{job="server-b"} / 1024 / 1024
```

---

## ğŸ§ª QUERIES PARA DURANTE TESTES DE CARGA

### Dashboard de Teste em Tempo Real

Cole estas queries em abas separadas do Prometheus durante o teste:

**Aba 1 - Throughput:**
```promql
sum(rate(p_api_requests_total[10s]))
```

**Aba 2 - LatÃªncia P95:**
```promql
histogram_quantile(0.95, rate(p_api_request_duration_seconds_bucket[1m])) * 1000
```

**Aba 3 - Erros:**
```promql
sum(rate(p_api_requests_total{status=~"5.."}[10s]))
```

**Aba 4 - RequisiÃ§Ãµes Ativas:**
```promql
p_api_active_requests
```

**Aba 5 - Load no Banco:**
```promql
server_a_db_connections_active
```

---

## ğŸ“Š QUERIES DE ANÃLISE PÃ“S-TESTE

### EstatÃ­sticas Gerais

```promql
# Total de requisiÃ§Ãµes durante o teste
sum(increase(p_api_requests_total[5m]))

# RequisiÃ§Ãµes por endpoint
sum by (endpoint) (increase(p_api_requests_total[5m]))

# Pico de throughput (req/s)
max_over_time(rate(p_api_requests_total[30s])[5m:30s])

# LatÃªncia mÃ©dia durante o teste
avg_over_time((rate(p_api_request_duration_seconds_sum[1m]) / rate(p_api_request_duration_seconds_count[1m]))[5m:])
```

### Identificar Gargalos

```promql
# Endpoint mais lento (latÃªncia P99)
topk(1, histogram_quantile(0.99, sum by (endpoint) (rate(p_api_request_duration_seconds_bucket[5m]))))

# Endpoint com mais erros
topk(1, sum by (endpoint) (rate(p_api_requests_total{status=~"5.."}[5m])))

# ServiÃ§o com maior latÃªncia
max(
  rate(p_api_request_duration_seconds_sum[1m]) / rate(p_api_request_duration_seconds_count[1m]),
  rate(server_a_grpc_request_duration_seconds_sum[1m]) / rate(server_a_grpc_request_duration_seconds_count[1m]),
  rate(server_b_grpc_request_duration_seconds_sum[1m]) / rate(server_b_grpc_request_duration_seconds_count[1m])
)
```

---

## ğŸ¯ QUERIES POR CENÃRIO DE TESTE

### CenÃ¡rio 1: Teste de Stress (Alta Carga)

**Monitorar:**
```promql
# 1. Sistema estÃ¡ aguentando?
rate(p_api_requests_total[10s]) > 0

# 2. LatÃªncia estÃ¡ aumentando?
histogram_quantile(0.95, rate(p_api_request_duration_seconds_bucket[30s])) * 1000

# 3. ConexÃµes no banco estÃ£o saturando?
server_a_db_connections_active

# 4. Taxa de erro estÃ¡ crescendo?
(sum(rate(p_api_requests_total{status=~"5.."}[30s])) / sum(rate(p_api_requests_total[30s]))) * 100
```

### CenÃ¡rio 2: Teste de Pico (Burst)

**Monitorar:**
```promql
# 1. RequisiÃ§Ãµes ativas (deve voltar a 0 apÃ³s o pico)
p_api_active_requests

# 2. Pico de throughput atingido
max_over_time(rate(p_api_requests_total[10s])[2m:10s])

# 3. RecuperaÃ§Ã£o apÃ³s pico (deve estabilizar)
rate(p_api_request_duration_seconds_sum[30s]) / rate(p_api_request_duration_seconds_count[30s])
```

### CenÃ¡rio 3: Teste de ResistÃªncia (Soak Test)

**Monitorar ao longo do tempo:**
```promql
# 1. Vazamento de memÃ³ria? (deve ser constante)
process_resident_memory_bytes{job="p-api"} / 1024 / 1024

# 2. ConexÃµes nÃ£o liberadas? (deve ser estÃ¡vel)
server_a_db_connections_active

# 3. Performance degrada com tempo?
histogram_quantile(0.95, rate(p_api_request_duration_seconds_bucket[5m])) * 1000
```

---

## ğŸ” QUERIES AVANÃ‡ADAS

### ComparaÃ§Ã£o de MÃºltiplos ServiÃ§os

```promql
# LatÃªncia de todos os serviÃ§os lado a lado
(rate(p_api_request_duration_seconds_sum[1m]) / rate(p_api_request_duration_seconds_count[1m])) * 1000 or
(rate(server_a_grpc_request_duration_seconds_sum[1m]) / rate(server_a_grpc_request_duration_seconds_count[1m])) * 1000 or
(rate(server_b_grpc_request_duration_seconds_sum[1m]) / rate(server_b_grpc_request_duration_seconds_count[1m])) * 1000
```

### Top 5 Endpoints Mais Lentos

```promql
topk(5, 
  histogram_quantile(0.95, 
    sum by (endpoint) (rate(p_api_request_duration_seconds_bucket[5m]))
  )
) * 1000
```

### Taxa de Erro Agregada do Sistema

```promql
(
  sum(rate(p_api_requests_total{status=~"5.."}[1m])) +
  sum(rate(server_a_grpc_requests_total{status="error"}[1m])) +
  sum(rate(server_b_grpc_requests_total{status="error"}[1m]))
) / (
  sum(rate(p_api_requests_total[1m])) +
  sum(rate(server_a_grpc_requests_total[1m])) +
  sum(rate(server_b_grpc_requests_total[1m]))
) * 100
```

---

## ğŸ“‹ TEMPLATE PARA RELATÃ“RIO DE TESTE

ApÃ³s fazer o teste de carga, documente com estas queries:

```markdown
## RelatÃ³rio de Teste de Carga

**Data:** [data]
**DuraÃ§Ã£o:** [tempo]
**Carga aplicada:** [req/s]

### MÃ©tricas Gerais
- Total de requisiÃ§Ãµes: `sum(increase(p_api_requests_total[5m]))`
- Throughput mÃ©dio: `avg_over_time(rate(p_api_requests_total[1m])[5m:])`
- Throughput mÃ¡ximo: `max_over_time(rate(p_api_requests_total[30s])[5m:30s])`

### LatÃªncia
- P50: `histogram_quantile(0.50, rate(p_api_request_duration_seconds_bucket[5m])) * 1000` ms
- P95: `histogram_quantile(0.95, rate(p_api_request_duration_seconds_bucket[5m])) * 1000` ms
- P99: `histogram_quantile(0.99, rate(p_api_request_duration_seconds_bucket[5m])) * 1000` ms

### Erros
- Taxa de erro: `(sum(rate(p_api_requests_total{status=~"5.."}[5m])) / sum(rate(p_api_requests_total[5m]))) * 100` %

### Recursos
- CPU mÃ¡xima: `max_over_time(rate(process_cpu_seconds_total[1m])[5m:]) * 100` %
- MemÃ³ria mÃ¡xima: `max_over_time(process_resident_memory_bytes[5m:]) / 1024 / 1024` MB
- ConexÃµes DB mÃ¡ximas: `max_over_time(server_a_db_connections_active[5m:])`

### ConclusÃ£o
[AnÃ¡lise dos resultados]
```

---

## ğŸ’¡ DICAS DE USO

1. **Use `[1m]` para dados em tempo real** durante o teste
2. **Use `[5m]` para anÃ¡lise pÃ³s-teste** (mais suave)
3. **Sempre multiplique por 1000** para converter segundos em milissegundos
4. **Use `increase()` para contar eventos** num perÃ­odo
5. **Use `rate()` para ver velocidade** (eventos por segundo)
6. **Percentis > MÃ©dia** - P95 e P99 sÃ£o mais importantes que avg

---

## ğŸ“ ENTENDENDO OS RESULTADOS

### Throughput (RequisiÃ§Ãµes/segundo)
- **< 10 req/s**: Baixo, teste local
- **10-100 req/s**: MÃ©dio, aplicaÃ§Ã£o pequena
- **100-1000 req/s**: Alto, aplicaÃ§Ã£o de produÃ§Ã£o
- **> 1000 req/s**: Muito alto, sistema enterprise

### LatÃªncia
- **< 100ms**: Excelente â­â­â­
- **100-300ms**: Bom â­â­
- **300-500ms**: AceitÃ¡vel â­
- **> 500ms**: Precisa otimizar âš ï¸

### Taxa de Erro
- **< 0.1%**: Excelente
- **0.1-1%**: AceitÃ¡vel
- **1-5%**: AtenÃ§Ã£o necessÃ¡ria
- **> 5%**: Problema crÃ­tico

---

**Pronto para testar! ğŸš€**

Copie as queries acima diretamente no Prometheus (http://localhost:9090) e analise seus resultados!
